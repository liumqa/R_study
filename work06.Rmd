---
title: "作业06：Machine Learning"
author: "qinluoao"
date: "2017/8/11"
output:
  pdf_document:
    highlight: tango
    includes:
      in_header: header.tex
    keep_tex: yes
    latex_engine: xelatex
  html_document:
    highlight: haddock
  word_document: default
---

##1.机器学习定义
机器学习研究的是如何赋予计算机在没有被明确编程的情况下仍能够学习的能力，让计算机“ learn from experience”，能自动获取与整合知识的一套系统。

##2.机器学习工作流程（类似cross-industry standard process for data mining)

###2.0业务理解
定义研究问题，梳理业务流程、逻辑、指标体系，明确分析目标。

###2.1数据获取
确定取数目的、数据用途、数据量、时间范围（周期）。对数据进行探索，包括数据描述性统计、可视化探索、数据质量探索（数据缺失值、异常值、重复值情况）

###2.2数据预处理
数据整理：包括新建列、数据合并、构造子集、数据排序、数据分组、数据规范化等。
数据清洗：缺失值、异常值、重复值处理，数据格式转换等。数据预处理常涉及的包：字符处理stringr包、日期变换lubridate包、数据操作的dplyr包、数据清理的tidyr包、可视化ggplot2包等，最终形成满足分析需求的多维度、格式正确的宽表。

###2.3特征选择
特征选择是指选择获得相应模型和算法最好性能的特征集，决定了机器学习的上限。特征选择的作用：
• Improve the accuracy of a machine learning algorithm
• Boost model performance for high-dimensional data sets
• Improve model interpretability
• Prevent overftting
常见的处理有：

####a.数据降维度
降低数据维度，常用主成分分析、因子分析、奇异值分解等方法。

####b.显著性检验
目的是剔除显著性低的自变量，如删除常数自变量、删除方差极小的自变量

####c.强相关性检验
指的是某自变量与其他自变量有很强的相关性

####d.多重共线性检验
剔除自变量中多重共线性的变量，用VIF(方差膨胀因子)来检验多重共线性问题、偏相关系数来处理

###2.4建模及模型训练
根据想要获得的数据洞察、数据的大小、算法的内存需求、算法计算速度、准确度和易用性等来选择模型。
模型建立后需要对模型性能进行评估，常采用交叉验证思想，交叉验证形式有K-fold cross-validation验证和留一验证等。

###2.5模型评估
通过不断对比尝试、反复迭代建立最优的模型。对分类算法模型评估的方法有：混淆矩阵confusion matrix和ROC曲线。

##3.机器学习算法

###3.1算法分类
![有监督和无监督学习算法](f:/Algorithm.png)

回归算法:学习预测连续

分类算法:学习决策边界

聚类算法:学习潜在模式和事物内在结构


###3.2如何选择算法
![机器学习算法选择流程图](F:/machine-learning-cheet-sheet.png)

###3.3算法优化

目的是提高模型准确性，避免过拟合，过拟合时模型无法区分有效数据和噪音。
涉及特征转换、超参数调整（识别最佳模型参数集的过程，控制机器学习算法如何匹配数据模型）等内容。







###4.应用案例
```{r}
library(caret)
#1.数据获取：鸢尾花数据集
data("iris")
iris.data <- iris
#2.1数据探索
str(iris.data)
head(iris.data)
summary(iris.data)  #查看数据集摘要信息
attach(iris.data)
percentage <- prop.table(table(Species))*100
freq <-table(Species)
cbind(freq,percentage)
#2.2可视化描述,理解变量分布
#2.2.1单变量可视化
##花瓣和花萼四个数值变量分布情况的箱线图
input.val <- iris.data[,1:4]
par(mfrow=c(1,4))
for(i in 1:4){
  boxplot(input.val[,i],main=names(iris.data)[i])
}
##因子变量直方图
par(mfrow=c(1,1))
output.val <- iris.data[,5]
plot(output.val)
#2.2.2多变量可视化--caret包featurePlot绘图
library(ellipse)
featurePlot(x=input.val,y=output.val,plot="ellipse")
featurePlot(x=input.val, y=output.val, plot = 'box')
#3.数据分析：训练集和测试集
#获取原数据集的80%的行索引号,返回行索引的0.8N*1的Resample1矩阵
validation.index <- createDataPartition(iris.data$Species, p=0.80, list=FALSE)
head(validation.index)
#构建80%训练集和20%的测试集
train.data <-iris.data[validation.index,]
validation.data <- iris.data[-validation.index,]
#4.建模
#4.1交叉验证：分为K-fold、留一验证，目的选择最优模型
control <- trainControl(method = 'cv',number = 10) #10-fold Cross-Validation
metric <-"Accuracy"
#4.2构建模型-分类算法选择
#LDA线性判别分类，CART分类与回归树，RF随机森林
#(1)线性算法：e1071包
library(e1071)
set.seed(7)
lda.model <- train(Species~.,data = train.data,method="lda",metric=metric,trControl=control)
#(2)非线性算法
library(rpart)
set.seed(7)
cart.model <- train(Species~., data=train.data, method="rpart", metric=metric, trControl=control)
#(3)Random Forest
library(randomForest)
set.seed(7)
rf.model <- train(Species~., data=train.data, method="rf", metric=metric, trControl=control)
#5 模型评估:选择最优算法
results.model <- resamples(list(lda=lda.model, cart=cart.model, rf=rf.model))
str(results.model)
summary(results.model)
dotplot(results.model)
#6 模型应用
#lda算法运用
pred.result <- predict(lda.model, validation.data)
#混淆矩阵评价分类效果：总体分类精度、Kappa系数
confusionMatrix(pred.result, validation.data$Species)
```

